{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rock42069/Beyond_The_Buzz/blob/main/ML_MODEL_for_beyond_the_buzz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BEYOND THE BUZZ**\n",
        "\n",
        "> CONTRIBUTER: Trijal Srivastava\n",
        "\n",
        " \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "Hi and welcome to my submission!\n",
        "I will try my best to keep an engaging commentary running with the code. The code represents my final solution, but with my text blocks I will try to give you some insight into how we reached this.\n",
        "\n",
        "Let's begin by importing necessary libraries.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cPZAAmtT55uJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QonrfPe5Tf6L"
      },
      "outputs": [],
      "source": [
        "#for handling data and ploting\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#for making neural network\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.activations import linear, relu, sigmoid\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "tf.autograph.set_verbosity(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next two blocks help extract data from the .csv files provided, and then use it for training the model, converting them into numpy arrays.\n"
      ],
      "metadata": {
        "id": "13ETyYxA6m9y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VV_tGUZdiykj"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/trainrprocessed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5oip3yJ1q-dC"
      },
      "outputs": [],
      "source": [
        "numerical_cols = ['PARAMETER_1', 'PARAMETER_2', 'PARAMETER_3', 'PARAMETER_4', 'PARAMETER_5', 'PARAMETER_6', 'PARAMETER_7', 'PARAMETER_8', 'PARAMETER_9']\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train[numerical_cols] = scaler.fit_transform(train[numerical_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I have checked the correlation between the parameters, as it is clear from the obtained matrix that there is no correlation between any of the variables"
      ],
      "metadata": {
        "id": "x7zQ563E7XiW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HRTf4sqitS4o"
      },
      "outputs": [],
      "source": [
        "corr_matrix = train.corr()\n",
        "#corr_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have stored all parameters in a numpy array named data and all the verdicts in a numpy array named y_array"
      ],
      "metadata": {
        "id": "Gw1ZwwX07zpC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cAHOByqhq-yK"
      },
      "outputs": [],
      "source": [
        "y_array = train['VERDICT'].values\n",
        " \n",
        "data = train[['PARAMETER_1', 'PARAMETER_2','PARAMETER_3','PARAMETER_4','PARAMETER_5','PARAMETER_6','PARAMETER_7','PARAMETER_8','PARAMETER_9']].values\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I have modeled the neural nets. They are powerful universal function approximators, and amongst all the models we used this one, gave the best results."
      ],
      "metadata": {
        "id": "DeZLHFiV8Drs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6hu3QYggWBZ2"
      },
      "outputs": [],
      "source": [
        "model = Sequential(\n",
        "    [               \n",
        "        tf.keras.Input(shape=(9,)),    \n",
        "        Dense(128,activation ='relu'),\n",
        "        Dense(64,activation ='relu'),\n",
        "        Dense(32,activation ='relu'),\n",
        "        Dense(1,activation ='sigmoid')\n",
        "        \n",
        "        \n",
        "      \n",
        "    ], name = \"my_model\" \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Found the best architecture for our Neural Network by trial-and-error (not shown here). I observed that having 3 layers improved both the training and validation loss as compared to 2 layers, and adding an extra 4th layer worsened the validation loss due to overfitting of data. The number of neurons in each layer was determined by trying several variations. On making 128 neurons in one of the layers, we were able to minimize loss satisfactorily. \n",
        "\n",
        "I tried several learning rates and settled on 0.001 because decreasing it further was significantly increasing the training time without much improvement on the results. "
      ],
      "metadata": {
        "id": "QDfnW12v8l0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "n_splits = 5\n",
        "test_size = 0.2\n",
        "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
        "for train_index, test_index in sss.split(data, y_array):\n",
        "    X_train, X_test = data[train_index], data[test_index]\n",
        "    y_train, y_test = y_array[train_index], y_array[test_index]"
      ],
      "metadata": {
        "id": "7Bb9eW6JTplM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYFWTMXmh7pl",
        "outputId": "0de776ea-32ed-4452-8c9b-8fa3d81b8093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "262/262 [==============================] - 2s 2ms/step - loss: 0.2665 - accuracy: 0.9302\n",
            "Epoch 2/30\n",
            "262/262 [==============================] - 1s 2ms/step - loss: 0.2245 - accuracy: 0.9416\n",
            "Epoch 3/30\n",
            "262/262 [==============================] - 1s 2ms/step - loss: 0.2201 - accuracy: 0.9416\n",
            "Epoch 4/30\n",
            "262/262 [==============================] - 1s 3ms/step - loss: 0.2177 - accuracy: 0.9415\n",
            "Epoch 5/30\n",
            "262/262 [==============================] - 1s 4ms/step - loss: 0.2151 - accuracy: 0.9415\n",
            "Epoch 6/30\n",
            "262/262 [==============================] - 1s 4ms/step - loss: 0.2135 - accuracy: 0.9416\n",
            "Epoch 7/30\n",
            "262/262 [==============================] - 2s 7ms/step - loss: 0.2116 - accuracy: 0.9417\n",
            "Epoch 8/30\n",
            "262/262 [==============================] - 2s 7ms/step - loss: 0.2110 - accuracy: 0.9416\n",
            "Epoch 9/30\n",
            "262/262 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9420\n",
            "Epoch 10/30\n",
            "262/262 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9423\n",
            "Epoch 11/30\n",
            "262/262 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9421\n",
            "Epoch 12/30\n",
            "262/262 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9420\n",
            "Epoch 13/30\n",
            "262/262 [==============================] - 1s 5ms/step - loss: 0.2062 - accuracy: 0.9421\n",
            "Epoch 14/30\n",
            "262/262 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9422\n",
            "Epoch 15/30\n",
            "262/262 [==============================] - 1s 5ms/step - loss: 0.2036 - accuracy: 0.9424\n",
            "Epoch 16/30\n",
            "262/262 [==============================] - 1s 4ms/step - loss: 0.2028 - accuracy: 0.9426\n",
            "Epoch 17/30\n",
            "262/262 [==============================] - 1s 4ms/step - loss: 0.2022 - accuracy: 0.9425\n",
            "Epoch 18/30\n",
            "262/262 [==============================] - 1s 4ms/step - loss: 0.2006 - accuracy: 0.9423\n",
            "Epoch 19/30\n",
            "262/262 [==============================] - 2s 8ms/step - loss: 0.2004 - accuracy: 0.9426\n",
            "Epoch 20/30\n",
            "262/262 [==============================] - 2s 9ms/step - loss: 0.1987 - accuracy: 0.9427\n",
            "Epoch 21/30\n",
            "262/262 [==============================] - 1s 5ms/step - loss: 0.1984 - accuracy: 0.9426\n",
            "Epoch 22/30\n",
            "262/262 [==============================] - 1s 5ms/step - loss: 0.1975 - accuracy: 0.9426\n",
            "Epoch 23/30\n",
            "262/262 [==============================] - 1s 3ms/step - loss: 0.1965 - accuracy: 0.9429\n",
            "Epoch 24/30\n",
            "262/262 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.9422\n",
            "Epoch 25/30\n",
            "262/262 [==============================] - 1s 2ms/step - loss: 0.1953 - accuracy: 0.9425\n",
            "Epoch 26/30\n",
            "262/262 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.9430\n",
            "Epoch 27/30\n",
            "262/262 [==============================] - 1s 2ms/step - loss: 0.1929 - accuracy: 0.9427\n",
            "Epoch 28/30\n",
            "262/262 [==============================] - 1s 2ms/step - loss: 0.1920 - accuracy: 0.9430\n",
            "Epoch 29/30\n",
            "262/262 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.9428\n",
            "Epoch 30/30\n",
            "262/262 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.9427\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics = ['accuracy']\n",
        "\n",
        ")\n",
        "\n",
        "history= model.fit(\n",
        "    X_train,y_train,\n",
        "    batch_size=90,\n",
        "    epochs=30\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(X_test)\n",
        "prediction = np.where(prediction >= 0.5, 1, 0)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Print the evaluation results\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo18evfUsC9n",
        "outputId": "a46c0b03-01c9-4df0-e588-fba05dd5f88f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "185/185 [==============================] - 0s 1ms/step\n",
            "185/185 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9399\n",
            "Test loss: 0.20791491866111755\n",
            "Test accuracy: 0.939949095249176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PERFORMANCE\n",
        "Here we have tested our data using various performance metrics just for personal reference.\n"
      ],
      "metadata": {
        "id": "BBW58eczDUH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "auc_roc = roc_auc_score(y_test, prediction)\n",
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(y_test, prediction)\n",
        "\n",
        " \n",
        "\n",
        "print(\"AUC-ROC: \", auc_roc)\n",
        "print(\"F1 Score: \", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj7do0Tx7KB9",
        "outputId": "b30b7d66-b28d-404b-b5bc-4b50b0e4267a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-ROC:  0.5086431629750349\n",
            "F1 Score:  0.9690071791279987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "i4vGR26JRp47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c91cc00-5b51-47f8-f1db-76c41b9ec217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1842/1842 [==============================] - 3s 1ms/step\n",
            "2405 56516\n"
          ]
        }
      ],
      "source": [
        "test = pd.read_csv('/content/test.csv')\n",
        "data_test = test[['PARAMETER_1', 'PARAMETER_2','PARAMETER_3','PARAMETER_4','PARAMETER_5','PARAMETER_6','PARAMETER_7','PARAMETER_8','PARAMETER_9']].values\n",
        "prediction = model.predict(data_test)\n",
        "prediction = np.where(prediction >= 0.5, 1, 0)\n",
        "\n",
        "\n",
        "s0 = 0\n",
        "s1 = 0\n",
        "\n",
        "for i in range(len(prediction)):\n",
        "    if prediction[i] == 0:\n",
        "        s0 += 1\n",
        "    else:\n",
        "        s1 +=1\n",
        "print(s0,s1)\n",
        "prediction = prediction.reshape(-1)\n",
        "df = pd.DataFrame({'Prediction': prediction})\n",
        "df.to_csv('predictions.csv', index=False)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
